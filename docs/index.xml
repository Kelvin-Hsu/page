<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kelvin Hsu</title>
    <link>https://kelvin-hsu.github.io/page/</link>
    <description>Recent content on Kelvin Hsu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Sep 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://kelvin-hsu.github.io/page/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Best Student Paper Award at the European Conference on Machine Learning 2018</title>
      <link>https://kelvin-hsu.github.io/page/blog/best-student-paper-award-ecml-2018/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kelvin-hsu.github.io/page/blog/best-student-paper-award-ecml-2018/</guid>
      <description>At the welcome reception during the first night of the conference, our paper was announced the Best Student Paper Award Winner at the European Conference on Machine Learning 2018!
My talk was originally scheduled two days later for 20 minutes. With this announcement though, this meant that my talk was to be presented to the entire conference, moved 1 day earlier to the very next morning, and also doubled in time to 40 minutes.</description>
    </item>
    
    <item>
      <title>Hyperparameter Learning for Conditional Mean Embeddings with Rademacher Complexity Bounds</title>
      <link>https://kelvin-hsu.github.io/page/portfolio/hyperparameter-learning-for-conditional-mean-embeddings-with-rademacher-complexity-bounds/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kelvin-hsu.github.io/page/portfolio/hyperparameter-learning-for-conditional-mean-embeddings-with-rademacher-complexity-bounds/</guid>
      <description>Abstract  Conditional mean embeddings are nonparametric models that encode conditional expectations in a reproducing kernel Hilbert space. While they provide a flexible and powerful framework for probabilistic inference, their performance is highly dependent on the choice of kernel and regularization hyperparameters. Nevertheless, current hyperparameter tuning methods predominantly rely on expensive cross validation or heuristics that is not optimized for the inference task. For conditional mean embeddings with categorical targets and arbitrary inputs, we propose a hyperparameter learning framework based on Rademacher complexity bounds to prevent overfitting by balancing data fit against model complexity.</description>
    </item>
    
    <item>
      <title>Dean&#39;s Faculty Award for Outstanding Tutoring</title>
      <link>https://kelvin-hsu.github.io/page/blog/deans-faculty-award-for-outstanding-tutoring/</link>
      <pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kelvin-hsu.github.io/page/blog/deans-faculty-award-for-outstanding-tutoring/</guid>
      <description>The greatest gift from the act of teaching is the lesson of empathy. Before someone can understand you, you must first understand them.
Teaching has truly taught me so many important lessons. It teaches me about the beauty of constrasting experiences and thoughts. It teaches me about that communication is always a two way street. It teaches me that the audience and their frame of mind is always the most critical to the success and effectiveness of a presentation.</description>
    </item>
    
  </channel>
</rss>